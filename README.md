News-CategoryClassification - Text classification using Naive Bayes classifier

1.	First load the json file
2.	See the unique categories
3.	Give the category id for each category
4.	Draw the pie chart to show count of articles in each category
5.	We can plot bar graph to visualize the categories and number of headlines belonging to respective category
6.	We need to drop the columns which are not needed so that its easy to train.
7.	We can see the data, before and after cleaning.
8.	Data cleaning: This means to remove punctuations and covert to lower case
9.	We need to now filter the data
10.	Now we need to split the data into 80% Train, 20% Dev Data, 20% Test data
11.	We can also see the count of each headline in each category
12.	We need to separate features and targets
13.	Caculate the prior probabilities for two categories Crime and Entertainment
14.	We need to build vocabulary list
15.	We can use this vocabulary and create a dictionary
16.	We need to now find frequency/probability of each word - This is advantage of Naive Bayes
17.	Find conditional probability
18.	Find Top words of category = crime
19.	Find Top words of category = entertainment
20.	Since we got conditional probability, we will now find the prediction
21.	Split the dataset into given folds, use dev dataset.
22.	Find conditional probability with smoothing effect. This is advantage of Naive Bayes.
23.	Apply laplace smoothing
24.	Find prediction after smoothing. Draw graph to show effects after smoothing and comparing changes

